<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>convers.ations - tester view</title>
    <link rel="stylesheet" href="style_tester.css" />
    <script src="jquery-1.8.3.min.js"></script>
</head>

<body>

<main>
    <div id="result"></div>
    <button id="button"></button>
    <p id="message" hidden aria-hidden="true">
        Your browser doesn't support Speech Recognition.
    </p>
</main>

<script type="text/javascript">

    // create object to send to JSON file
    let session = {
        "SpeechRecognitionAlternative": [],
    };
    let maxLengthSession = 50;
    let counter = 0;

    window.addEventListener("DOMContentLoaded", () => {
        // HTML formatting
        const button = document.getElementById("button");
       const result = document.getElementById("result");
       const main = document.getElementsByTagName("main")[0];

        // include Web Speech API
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        // start listening if the button is pressed
        if (typeof SpeechRecognition === "undefined") {
            button.remove();
             const message = document.getElementById("message");
             message.removeAttribute("hidden");
             message.setAttribute("aria-hidden", "false");
        } else {
            let listening = false;
            const recognition = new SpeechRecognition();
            const start = () => {
                recognition.start();
                main.classList.add("speaking");
            };

            const stop = () => {
                recognition.stop();
                main.classList.remove("speaking");
            };

            // send results to the tester console and JSON file
            const onResult = event => {
                if (session.SpeechRecognitionAlternative.length >= maxLengthSession) session.SpeechRecognitionAlternative.length = (maxLengthSession - 1);
                session.SpeechRecognitionAlternative.splice(0,0,{"transcript": event.results[event.results.length - 1][0].transcript, "confidence": event.results[event.results.length - 1][0].confidence, "isFinal": event.results[event.results.length - 1].isFinal})

                if (!session.length){
                    printConsole(); //print results in the console log
                    printHTML(); // print results on the webpage
                    aj(session); // post newly updated array to JSON file (include last isFinal res if listening = false)
                }
            };
            recognition.continuous = true; // give continuous access to the mic
            recognition.interimResults = true; // print also non-Final results
            //recognition.maxAlternatives = 1; //will this help?
            //recognition.lang = 'en-US'; // specify language preference
            recognition.addEventListener("result", onResult);

            // activate/stop system by pressing the button
            button.addEventListener("click", () => {
                listening ? stop() : start();
                listening = !listening;
            });
        }

        //copy and print altered format of data event.results into console HTML
        function printConsole(){
            if (session.SpeechRecognitionAlternative[0].isFinal) {
                console.group("SpeechRecognitionResult{}:");
                console.log("transcript: %o", session.SpeechRecognitionAlternative[0].transcript);
                console.log("confidence: %o ", session.SpeechRecognitionAlternative[0].confidence);
                console.log("isFinal: %o", session.SpeechRecognitionAlternative[0].isFinal);
                console.groupEnd();
            } else {
                console.group("SpeechRecognitionAlternative{}:");
                console.log("transcript: %o",  session.SpeechRecognitionAlternative[0].transcript);
                console.log("confidence: %o ", session.SpeechRecognitionAlternative[0].confidence);
                console.log("isFinal: %o", session.SpeechRecognitionAlternative[0].isFinal);
                console.groupEnd();

            }
        }


        function printHTML(){
            result.innerHTML = "";

            //print in HTML: create new objects for data
            const text = document.createTextNode(" ");
            const p1 = document.createElement("p");

            //print in HTML: filtered data: finalResult text + confidence
            p1.appendChild(text);
            result.appendChild(p1);
        }

        // post data to server
        function aj(jsData){
            $.ajax({
                url: 'http://127.0.0.1:8090/',
                //dataType: "jsonp", // linked to the callback function
                data:   JSON.stringify(jsData, null, 2),
                type: 'POST',
                //jsonpCallback: 'callback', // this is not relevant to the POST   anymore

                success: function (data) {
                    let ret = jQuery.parseJSON(data);
                    $('#lblResponse').html(ret.message);
                },
                error: function (xhr, status, error) {
                    console.log('Error: ' + error.message);
                    $('#lblResponse').html('Error connecting to the server.');

                },
            });
        }

    });

</script>

</body>

</html>
