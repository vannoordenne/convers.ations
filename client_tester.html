<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>convers.ations - tester view</title>
    <link rel="stylesheet" href="style_tester.css" />
    <script src="jquery-1.8.3.min.js"></script>
</head>

<body>

<header>
    <h1>convers.ations - tester view</h1>
</header>

<main>
    <button id="button">start listening</button>
    <div id="result"></div>
    <div id="confidence_id"></div>
    <p id="message" hidden aria-hidden="true">
        Your browser doesn't support Speech Recognition.
    </p>
</main>

<script type="text/javascript">

    // create object to send to JSON file
    let session = {
        "SpeechRecognitionAlternative": [],
    };

    window.addEventListener("DOMContentLoaded", () => {
        // HTML formatting
        const button = document.getElementById("button");
        const result = document.getElementById("result");
        const main = document.getElementsByTagName("main")[0];

        // include Web Speech API
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition

        // start listening if the button is pressed
        if (typeof SpeechRecognition === "undefined") {
            button.remove();
            const message = document.getElementById("message");
            message.removeAttribute("hidden");
            message.setAttribute("aria-hidden", "false");
        } else {
            let listening = false;
            const recognition = new SpeechRecognition();
            const start = () => {
                recognition.start();
                button.textContent = "stop listening";
                main.classList.add("speaking");
            };

            const stop = () => {
                recognition.stop();
                button.textContent = "start listening";
                main.classList.remove("speaking");
            };

            // send results to the tester console and JSON file
            const onResult = event => {
                for (const res of event.results) {
                    printConsole(res);
                    printHTML(res); // print results on the webpage
                    jsonExp(res[0].transcript, res[0].confidence, res.isFinal);
                }
            };

            recognition.continuous = true; // give continuous access to the mic
            recognition.interimResults = true; // print also non-Final results
            //recognition.lang = 'en-US'; // specify language preference
            recognition.addEventListener("result", onResult);

            // activate/stop system by pressing the button
            button.addEventListener("click", () => {
                listening ? stop() : start();
                listening = !listening;
            });
        }

        //copy and print altered format of data event.results into console HTML
        function printConsole(res){
            if(res.isFinal){
                console.group("%cSpeechRecognitionResult{}:", "font-weight: bold");
                console.log("%ctranscript: " + res[0].transcript, "font-weight: bold");
                console.log("%cconfidence: " + res[0].confidence, "font-weight: bold");
                console.log("%cisFinal: " + res.isFinal,"font-weight: bold");
                console.groupEnd();
            } else {
                console.group("SpeechRecognitionAlternative{}:");
                console.log("transcript: " + res[0].transcript);
                console.log("confidence: " + res[0].confidence);
                console.log("isFinal: " + res.isFinal);
                console.groupEnd();
            }
        }

        function printHTML(res){
            result.innerHTML = "";
            confidence_id.innerHTML = "";

            //print in HTML: create new objects for data
            const text = document.createTextNode(res[0].transcript);
            const p1 = document.createElement("p");
            const confidence = document.createTextNode(res[0].confidence);
            const p2 = document.createElement("p");

            //print in HTML: filtered data: finalResult text + confidence
            p1.appendChild(text);
            p2.appendChild(confidence);
            result.appendChild(p1);
            confidence_id.appendChild(p2);
        }

        // export transcript, confidence and isFinal to JSON
        function jsonExp(getTranscript, getConfidence, getFinal){
            session.SpeechRecognitionAlternative.push({"transcript": getTranscript, "confidence": getConfidence, "isFinal": getFinal});
            aj(session);
        }

        // post data to server
        function aj(jsData){
            $.ajax({
                url: 'http://127.0.0.1:8090/',
                //dataType: "jsonp", // linked to the callback function
                data:   JSON.stringify(jsData, null, 2),
                type: 'POST',
                //jsonpCallback: 'callback', // this is not relevant to the POST   anymore

                success: function (data) {
                    let ret = jQuery.parseJSON(data);
                    $('#lblResponse').html(ret.message);
                },
                error: function (xhr, status, error) {
                    console.log('Error: ' + error.message);
                    $('#lblResponse').html('Error connecting to the server.');

                },
            });
        };
    });

</script>

</body>

</html>
